mongo "mongodb://m123-rs1-shard-00-00-glprg.mongodb.net:27017,m123-rs1-shard-00-01-glprg.mongodb.net:27017,m123-rs1-shard-00-02-glprg.mongodb.net:27017/test?replicaSet=m123-rs1-shard-0" --ssl --authenticationDatabase admin --username khylo --password <PASSWORD>

mongo "mongodb://cluster0-shard-00-00-jxeqq.mongodb.net:27017,cluster0-shard-00-01-jxeqq.mongodb.net:27017,cluster0-shard-00-02-jxeqq.mongodb.net:27017/test?replicaSet=Cluster0-shard-0" --authenticationDatabase admin --ssl --username m001-student --password m001-mongodb-basics

mongorestore --drop --host $hostname --port 37017 --authenticationDatabase $authdb --ssl --username $username --gzip --password $password --dir mongodump-people-signup-score

Local Import
	mongoimport --db capc --collection RegisteredUser --drop --file ./jobs/data/users.json --jsonArray
	
	mongoimport --drop -d students -c grades grades.json
	
	
	mongorestore (restore from mongodump)
	
	mongotop  // top runnign jobs in monfo
	
	mongostat    / /statistics.. inserts queries updates or deletes
	
	//Shutdown mongod from mongo
	mongo admin --eval 'db.shutdownServer()'
	
	mongod  --fork --logpath [path[ .. start as a background process.. must specify logpath as well
	
	mongod --config /etc/mongod.conf
	
Loopback.
	look in server/datasources.json for db config. e.g.g mongo
	
CopyCollection
	from within mongod
		db.myoriginal.aggregate([ { $match: {} }, { $out: "mycopy" } ])
		db.movieDetails.aggregate([ { $match: {} }, { $out: "movie2" } ]) 
		
	from command line
		mongodump -d db -c sourcecollection 
		mongorestore -d db -c targetcollection --dir=dump/<db>/<sourcecollection.bson>
		
		db.collection.help().. show all commands

find
*Mongod will by default log slow queries. So shoudl set some automation up to find these in the logs and notify.*

	db.<collection>.find(<query>, [projection]).sort()
	Note can also append .explain() at end of query to get explainPlan
		query = { $<Operator(s)>  $gt, $lt, $gte, $in
				And used by default.
			db.inventory.find( { status: "A", qty: { $lt: 30 } } )
			
		Projections used to specify columns, This only returns _id and name
			coll = db.users; // example of shortcut using variables
			coll.find( { }, { name: true } )
		
		for or use
			db.inventory.find( { $or: [ { status: "A" }, { qty: { $lt: 30 } } ] } )
			db.inventory.find( { $or: [ { status: "A" }, { qty: { $lt: 30 } } ] } ).explain()
		
		Text find				
			db.product.find({$text:{$search: "My search string"}))
			
			Text find ORs search strings together so may give us unexpected results, so shoudl use
			db.product.find({$text:{$search: "My search string"}, {"score":{$meta:"textScore"}}).sort({score:{$meta:"TextScore"}})
			
		//Find countries with 2nd name Sweden
		db.movieDetails.find({'countries':'Sweden'}).count()
		
		**Note if you are filtering on 2 values of one field then be careful
		**Wrong
		db.movie2.find({"imdb.votes":{"$lt":10000}, "year":{"$lte":2013}, "year":{"$gte":2010}},{title:1, year:1, _id:0, "imdb.votes":1})
		This will only filter on year gte 2010 since it overrides the 2013
		**Right
		db.movie2.find({"imdb.votes":{"$lt":10000}, "year":{"$lte":2013, "$gte":2010}},{title:1, year:1, _id:0, "imdb.votes":1})

	Sort
		db.grades.find({type : "homework"}).sort({'student_id':1, score:1})  sort by student, then score after filtering only homework 'type'
		db.grades.find( { }, { 'student_id' : 1, 'type' : 1, 'score' : 1, '_id' : 0 } ).sort( { 'student_id' : 1, 'score' : 1 } ).limit( 5 )
	

	Explain
	After 3.0 format changed from db.people.find().explain
	to
	db.people.explain(). ...   find(), upother way preferreddate(),  aggregate , help      not insert
		return explainable object

	old format still works but first find() returns cursor   (can run next on this)  .. but 
	"allPlansExecution"

	Covered Query
		Query that can be fulfilled enturely by index.. e..g find must match index (eg. must project only index fields, or subset)
		much faster, only need to examine 1 key in index.. Noramlly 0 docs examined
		normally have to filter out _id field
	

		
		
	Index
	choosing index

		Mongo will identify some canditate indexes.
		Then run n theads in parallel doing the n qeries, and see which returns quicker (maybe simpler subset of query)
		Winning index is cached for future use
			indexes cache reevaluated afer
			Writes no longer do this .. After 1000 writes this may be re-evalued 
			Instead, we evict when the "works" of the first portion of the query exceed the number of "works" used to decide on the winning plan by a factor of 10x
			rebuild index
			Add or reomove another index
			or after restarat
			
    Need to keep Indexes in memory
		Size ?
			db.people.stats()

		make sure index can fit in memory for Perf reasons
	
		List
			db.stiudents.getIndexes();
		Delete	use key from list above
			db.students.dropIndex({'student_id':1}) // Can't delete _id
			
		Create
			db.student.ensureIndex({'teachers':1})
			
			db.student.createIndex({'teachers':1, 'class':-1})
			db.student.createIndex({'teachers':1, 'class':-1}, {unique:true})  // Can enforce unique/distinct values. Dupicate will cause error  Do getIndexes() to see if unique or not (_id is anomoly)
		
		verify
			db.students.explain().find({'teachers':{$all:[0,1]}})   
			
			Can put explain(true) to run query and get more info
				uses BtreeCursor Index for lookup
				
		for compound index
			e.g. surname, firstname, dob
				we can use this compound index to lookup on surname alone, then do full table scan for DOB
				but we can't lookup DOB o9r firstname alone. 
				
			Adding indexes makes writes slower. Pattern. Before large insert have no indexes. Add indexes after large write.

		MultiKey Index (e.g. on array)
			Can't have index on more than 1 field is array
			db.foo.createIndex( { a:1, b:1 } )
			
			but can create for 1 array per document 					
					Index expands all entries in collection to index, and maps them to other values in the index
					e.g.
						{a: 1, b:[1,2,3]}   ok
						{a:[2,3], b:5}		ok
						{a:[2,3], b:[5,4]}  Not Ok.. 2 arrays for field with index
						
					
			So if we add elements and make some fields arrays this may break indexes
			
		Sparse index .. can make a unique index on field that is not always present
			e.g.
		db.people.createIndex({'sparseField':1},{'unique':true, 'sparse':true})
		
		Regex
			If searching for regex, can only use Index iff searching for starts with  (/^searchString/ ) e.g.
			db.useres.find({username: /^kirby/})


		can create index in foreground or bacgrund

		forgound defalt.. blocking call, block DB and collection
			BLOCKS readers and writers to whole DB (... eg. use db)


		background
			slower
			but doesn't block queries (does block mongo shell, but other instances not blocked)
		db.people.createIndex({'sparseField':1},{'background':true})

		create index on different server first (out of mongo replica set)
			run index creation in foreground
			bring back into set
			it will spread?

			
		For indices subelements use dot notation, 
		
			db.people.createIndex({'work_history.company':-1})
			
			
	db.movieDetails.findOne
	or
	db.movieDetails.find
	Array
		Query family in list of genres
		> db.movieDetails.find({"genres":"Family"}).count()
		124
		Query family in 2nd position..
		> db.movieDetails.find({"genres.1":"Family"}).count()
		58
		
	Q. 2.7 (extra non homework)
		db.createCollection("testMovie")		
		db.testMovie.insert( [ {  some test film output from movieDetails, and change awards }])
		db.testMovie.find({"awards.oscars.award":{$eq:"bestPicture"}}).count()
		
		
		
	Aggregation
			db.grades.aggregate([{'$group':{'_id':'$student_id', 'average':{$avg:'$score'}}}, 
									{'$sort':{'average':-1}}, {'$limit':1}])	
		
		
	Assignment
		var myDoc = db.movieDetails.find({"imdb.id":"tt4368814"})

update.
	updateOne
	updateMany

	upsert

	> db.movieDetails.updateOne({title:"MyTestFilm"},{$set:{"title" :"MyTestFilm", "year" : 1982, "rated" : "PG", "runtime" : 113, "countries" : [ "USA" ], "genres" : [ "Action", "Adventure", "Drama" ], "director" : "Nicholas Meyer", "writers" : [ "Gene Roddenberry", "Harve Bennett", "Jack B. Sowards", "Jack B. Sowards" ], "actors" : [ "William Shatner", "Leonard Nimoy", "DeForest Kelley", "James Doohan" ], "plot" : "With the assistance of the Enterprise crew, Admiral Kirk must stop an old nemesis, Khan Noonien Singh, from using the life-generating Genesis Device as the ultimate weapon.","imdb" : { "id" : "tt0084726", "rating" : 7.7, "votes" : 86687 }, "metacritic" : 71, "awards" : { "wins" : 2, "nominations" : 9, "text" : "2 wins & 9 nominations." }, "type" : "movie" }},{upsert:true})
	
	$push - adds items in the order in which they were received. Also you can add same items several times
	$addToSet - adds just unique items, but order of items is not guarantied
	
Replace
	ReplaceOne
	replaceMany
	
Delete
	deleteOne
	deleteMany
	
	
	Scaling Horizintally. Sharded clusters
	
		mongos (routeres).. used for handling sharded clusters. Which is multiple replica sets (up to 12 at time of writing).
		when connecting to a mongos router.
			db.mongos.find({},  {_id:1})
			sh.status()
			sh.enableSharding("Test") // enable partiition is now true
			
		create shard key
			One per collection.. can't be changed once its in place
			https://docs.mongodb.com/manual/tutorial/choose-a-shard-key/?_ga=2.220197530.2030665551.1512995876-1430811341.1509531785
		
	
	Scaling veritically. 
		Rebuilds each component one by one.  to more powerful servers. e.g. moving from M10 cluster to M60 cluster.
	
	
	id  c
	00  54
	01  52
	10  22
	11 97
Aggregation
	Like groupBy and having
	Aggregation uses pipline.. filter / aggregate / sort ... steps within array
		
	Stages of pipeline
	
		$project  (select sub elements.. reshaping of document  1 doc -> 1 doc)
			$toUpper
			$toLower
			$multiply
		$match   filter  n: 1 ..   $gt $lt etc
		$group - aggregate .. sum / count .. n:10
					$sum
					$avg
					$min
					$max
					$push   push to array (no duplicate check )
					$addToSet   add to array, e.g. pull out list of categories for a group.. With Duplicate check
					$first   ... can use after sorting if you want the first`
					$last   .. .after sorting
		$sort    1:1  100MB limit for in-memory sort.. Can be done before or after grouping
		$skip   skips  n:1 only makes sense after sort
		$limit   limit  n:10 only makes sense after sort AND after skip
		$unwind - normalise data  1:n  e.g. array of tags   .. explodes data so we can use $group on it.
		$out   output
		$redact   security related to reduce docs useres see   n:1
		$geonear   reduce based on location  n:1
		
		
	** Examples
	// Group by manufactere (which is key on docs)
	db.products.aggregate(
	[{
		$group:{ _id:"$manufacturer", num_products: {$sum:1}	}
	}])
	
	//Can have useful name in _id if we want more clarity
	db.products.aggregate(	[{		$group:{ _id:{"maker":"$manufacturer"}, num_products: {$sum:1}	} 	}])
	
	//Can sum fields
	db.products.aggregate(	[{		$group:{ _id:{"maker":"$manufacturer"}, num_products: {$sum:$price}	} 	}])
	
	Avg
	db.zips.aggregate([{$group:{_id:"$state", "average_pop":{$avg:"$pop"}}}])
	
	Max
	db.zips.aggregate([{$group:{_id:"$state", "pop":{$max:"$pop"}}}])
	
	AddToSet
	db.zips.aggregate([{$group:{_id:"$city", "postal_codes_per_city":{$addToSet:"$_id"}}}])
	//Problem with above  is differnt cities with the same name but in different states are combined
	db.zips.aggregate([{$group:{_id:{City:"$city",State:"$state"}, "postal_codes_per_city":{$addToSet:"$_id"}}}])
	
	Double Group By  (Note 2nd is taking part of the key of the first)
	db.fun.aggregate([{$group:{_id:{a:"$a", b:"$b"}, c:{$max:"$c"}}}, {$group:{_id:"$_id.a", c:{$min:"$c"}}}])
	
	//Compund _id key in order to group by more than one field..
	db.products.aggregate(
	[{
		$group:{ _id:{"manufacturer":$manufacturer, "category", "$category"}, num_products: {$sum:1}	}
	}])
	
	//Project:
		db.zips.aggregate([{$project:{
			"_id":0,
			"city":{$toLower:"$city"}, 
			"pop":"$pop",
			"state":"$state",
			"zip":"$_id"
		}}])
		
		or
		
		db.zips.aggregate([{$project:{
			"_id":0,
			"city":{$toLower:"$city"}, 
			"pop":1,
			"state":1,
			"zip":"$_id"
		}}])
		
	// Match
	db.zips.aggregate([{$match:{state:"CA"}}])
	db.zips.aggregate([{$match:{pop:{"$gt":100000}}}])
	
	Sort
	//Sort by state/ city
	db.zips.aggregate([{$sort:{state:1, city:1}}])
	//sort by pop desc
	db.zips.aggregate([{$sort:{pop:-1}}])
	
	// First and Las .. must do another group to get them
	db.fun.aggregate([
		{$match:{a:0}},
		{$sort:{c:-1}},
		{$group:{_id:"$a", c:{$first:"$c"}}}
	])
	
	All In one
	use zips;
	db.zips.aggregate([	
		{$match:{state:"CA"}}, 
		{$group:{_id:"$city", pop:{$sum:"$pop"}, zip:{$push:"$_id"}}},
		{$project:{_id:0, city:"$_id", pop:1, zip:1}},
		{"$sort":{pop:-1}}
		])
		
	db.zips.aggregate([
		{$match:     {     state:"NY"     }    },
		{$group:     {     _id: "$city",     population: {$sum:"$pop"},     }    },
		{$project:     {     _id: 0,     city: "$_id",     population: 1,     }    },
		{$sort:     {     population:-1     }    },
	])
	
	cd aggregation/
	type "first_phase3_m101p.js" | mongo
		
	Homework
	//Which author has made most comments
	//5.1
	use blog;
	db.posts.aggregate([{$unwind:"$comments"},{$group:{"_id":"$comments.author", "numComments":{$sum:1}}},{$sort:{numComments:-1}}])
	
	//5.2
	//Average population in cities in CA and NY with populations > 25000
	// Wrong doesn't add up population for city .. .db.small_zips.aggregate([{$match:{state:{"$in":["CA","NY"]}, pop:{$gt:25000}}},{$project:{_id:0,city:1,state:1,pop:1}},{$group: {_id:"$state","avg":{$avg:"$pop"}}}])
	// This is correct
	db.small_zips.aggregate([{$group: {_id:{state:"$state","city":"$city"}, pop:{$sum:"$pop"}}},{$match:{"_id.state":{"$in":["CA","NY"]}, pop:{$gt:25000}}},{$project:{_id:0,city:"$_id.city",state:"$_id.state",pop:1}},{$group: {_id:"$state","avg":{$avg:"$pop"}}}])
	
	//5.3
	//average per studentPerClass to get average student score per class, then average per class, then sort
	db.grades.aggregate([{$unwind:"$scores"},{$match:{$or:[{"scores.type":"exam"},{"scores.type":"homework"}]}}, {$group:{"_id":{"student":"$student_id","class":"$class_id"}, avgPerStudentPerClass:{$avg:"$scores.score"}}}, 
		{$group:{"_id":"$_id.class", avgPerClass:{$avg:"$avgPerStudentPerClass"}}}, {$sort:{avgPerClass:-1}}])
		
	//5.4
	//
	use zips
	db.zips.aggregate([  {$project:     {    first_char: {$substr : ["$city",0,1]}, pop:"$pop"    }   },
						{$match:{first_char:{$in:["B","D","O","G","N","M"]}}},
						{$group:{"_id":null, total:{$sum:"$pop"}}}
		])
	
	
Replication and Sharding
	Writing
		Journal log of all events. Stored in memory and written to disk
		Journal write to disk is the main write
		
		by default normal write has w:1 and j:00
			this mean s that write is persisted but journal isn't by time of response.
			
			
				w | j  
		default 1 | 0    fast but small window where j is not written and data not fully persisted (replica set?)  
	            1 | 1  slower but safer
				0       very fast but no guarantees. Not recommended
				
				
			Network failures compound things.
				Inserts generally safe... 
				updates les so if using $sum etc. Safer to do a read first and then delete, and insert updated value
				
	Replication
		used for availibility 
		Replica Set  ... minimum 3 nodes to ensure election of new primary and to have redundancy
			Always write to primary
			
		Election
			Node types
				Normal 
				Arbiter (used only for voting .. e.g to maintain majority)
				Delayed / Regular .. can't vote. can't be pimary node  P=0
				Hidden .. cant be primary. Can Vote.. . Used to analytics      P=0
				
***
Performance	 .. https://university.mongodb.com/mercury/M201
***

	in Memory actions
		aggregation/ index traversing / write operations/ query engine / connections
		
	Hardware	
		
		Recommend RAID 10    (do not recommend RaID 0 / 5 /6  reduced performace)
					raid 10		=     raid 0
							   raid 1			raid 1
							   
		Can use multiple Disks. .allows IO load to be distributed and parallelized
		
		Wired Tiger is more CPU intensive but is the future
		
		
		mongod --directtoryperdb   this creates dir per db
			Allows these to be symbolic links and have these mapped to different drives since this can increase parallelism
			
	Indexes
	
		db.currentOp()    // show current running process e.g.g background index
		db.killOp() // e.g. kill background Op.
	
		Single Field Index
			db.people.createIndex({'ssn':1})
			
			Dont create index on sub document. Instead use dot notation to specify an elemnt of subDocument. Indexing on Docuemnt ineffefient if its a big Document
			
		Compount Index
			On multiple fields.   
			Rule of thumb  Equality  - Sort - Range
				Equality field before sort field before range field
			
			
		MultiKey Index e.g. on Arrays.. Creates Index key for each element in array. Be careful if using large arrays
			Can't use compund fields where more than one field is an array (per document)
			
		Text Index	  Pass in text keyword to help avoid collection scan. Creates index for every unique word in string. (spaces and hypens are tokenizer)
			db.product.createIndex({productName:"text"})  
			
			for searching use
			db.product.find({$text:{$search: "My search string"}))
		
		Partial Index .. used to save space if it makes sense. .Partial Index preferred over sparse
		 (General case of Sparse Index).. Can't have both sparse and Partil Key
			Can't have shard index as partial index
		 Be careful.. Find predicate must match partial index
		 // rerun the query (doesn't use the partial index) see performance/parial_index.js examples
			db.restaurants.find({'address.city': 'New York', 'cuisine': 'Sichuan'})

			// adding the stars predicate allows us to use the partial index
			exp.find({'address.city': 'New York', cuisine: 'Sichuan', stars: { $gt: 4.0 }})
	Explains
		Can create Explainable Object e.g.
			exp=db.people.explain("executionStats")  attche explain to collection so it gets run every time
		db.people.find({'ssn':"720-38-5636"}).explain("executionStats")
		
	WriteConcerns
		w: 1
		j: false  //journal
		wtimeout: 5 // ms
		
		e.g.g {w:"majority", j:"true"}
		
		
	Collations  See performance\collations.js   
		Language Specific rules for text searches
		
		locale, caseLevel, caseFirst, strength, numericOrdering, alternate, maxvarialbe, backwards
		Allows locales, case insentive (strength:1) searches
		Collation appears in explain results
		Can create Indexes for individual collations, e.g. en or pt, or it
		
		db.createCollection( "foreign_text", {collation: {locale: "pt"}})
		// insert an example document
		db.foreign_text.insert({ "name": "Máximo", "text": "Bom dia minha gente!"})
		// explain the following query (uses the Portuguese collation)
		db.foreign_text.find({ _id: {$exists:1 } } ).explain()
	
	
Profiling	have mongod log to db.system.profile
	mongod --profile [level] [--slowms 2]
	level
	0 default .. no logging
	1 log slow queries (can spcify --slowms )
	2 log all queries (maybe for dev)
	
	from mongo shell
	db.getProfilingLevel(	)
	db.setProfilingLevel(2)
	db.getProfilingStatus(	)
	db.setProfilingStatus(1,4) 		// Level 1:  4 ms
	
	Can then query profile table 
	 db.system.profile.find( { millis : { $gt:1000 } } ).sort( { ts : -1 } )
	
	Homework
		Lab 2.1 got wrong. 
		Heres what I think is the right answer now (* marks where index used for both search and sort)
			When you see SORT_KEY_GENERATOR that is not using Index I believe
		
		var exp = db.people.explain("executionStats")
		exp.find({ "address.city": "West Cindy"}).sort({"address.city":-1})
		exp.find({ "first_name": "Jessica", "address.state": { $lt: "S"}}).sort({"address.city":1})
		*exp.find({ "address.state": "South Dakota", "first_name": "Jessica"}).sort({"address.city":-1})
		*exp.find({ "first_name": "Jessica"}).sort({"address.state":1,"address.city":1})
		exp.find({ "first_name": {$gt:"J"}}).sort({"address.city":-1})
		 
		 
		 Java
		db.posts.createIndex({date:-1})
		db.posts.createIndex({tags:1})
		db.posts.createIndex({permalink:1})
		
		db.sysprofile.find({'op':'query',ns:'school2.students'}).sort({millis:-1 } ).limit(2).pretty()
		
		
Examples

stop mongod
use admin
db.shutdownServer()
quit()

    Create user
mongo admin --host localhost:27000 --eval '
  db.createUser({
    user: "m103-admin",
    pwd: "m103-pass",
    roles: [
      {role: "root", db: "admin"}
    ]
  })
'
mongo --port 27000 ;--username m103-admin --password m103-pass -authenticationDatabase admin
use admin
db.createUser({user:'m103-application-user',
pwd:'m103-application-pass', roles:['readWrite'], db:'applicationData',)
mongo admin --host localhost:27000 --eval '
  db.createUser({
    user: "m103-application-user",
    pwd: "m103-application-pass",
    roles: [
      {role: "readWrite", db: "applicationData"}
    ]
  })
'
mongoimport --port 27000 -d applicationData -c products -u m103-application-user -p m103-application-pa
ss --authenticationDatabase=admin dataset/products.json


mongo --eval "load('products__m101.js')"		